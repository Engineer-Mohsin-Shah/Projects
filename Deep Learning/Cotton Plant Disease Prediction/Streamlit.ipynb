{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e34f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e801c132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1707 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory = \"Cotton Plant Disease Dataset\",\n",
    "    shuffle = True,\n",
    "    label_mode = 'int',\n",
    "    batch_size = 16,\n",
    "    image_size = (256,256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92389748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bacterial Blight', 'Curl Virus', 'Fussarium Wilt', 'Healthy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = dataset.class_names\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1024a4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class = len(class_name)\n",
    "n_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40086076",
   "metadata": {},
   "source": [
    "### Divide the Dataset into Train, Test, Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e33f80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 10, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The size of train dataset is 80%\n",
    "# The size of test dataset is 10%\n",
    "# The size of valid dataset is 10%\n",
    "\n",
    "train_datasize = int(0.8*len(dataset))\n",
    "test_datasize = int(0.1*len(dataset))\n",
    "valid_datasize = int(0.1*len(dataset))\n",
    "\n",
    "train_datasize, test_datasize, valid_datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d7b3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset lenght = 85\n",
      "Test Dataset lenght = 10\n",
      "Valid Dataset lenght = 12\n"
     ]
    }
   ],
   "source": [
    "Train_dataset = dataset.take(train_datasize)\n",
    "Test_dataset = dataset.skip(train_datasize).take(test_datasize)\n",
    "Valid_dataset = dataset.skip(train_datasize+test_datasize)\n",
    "print(f\"Train Dataset lenght = {len(Train_dataset)}\\nTest Dataset lenght = {len(Test_dataset)}\\nValid Dataset lenght = {len(Valid_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84565d95",
   "metadata": {},
   "source": [
    "### Through a function we also splite the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e4a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size, test_size, valid_size, shuffle = True, shuffle_size = 10000):\n",
    "  dataset_size = len(dataset)\n",
    "\n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(shuffle_size, seed = 15)\n",
    "\n",
    "  train_datasize = int(train_size*dataset_size)\n",
    "  test_datasize = int(test_size*dataset_size)\n",
    "  valid_datasize = int(valid_size*dataset_size)\n",
    "\n",
    "  Train_dataset = dataset.take(train_datasize)\n",
    "  Test_dataset = dataset.skip(train_datasize).take(test_datasize)\n",
    "  Valid_dataset = dataset.skip(train_datasize+test_datasize)\n",
    "\n",
    "  return Train_dataset, Test_dataset, Valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89a827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset lenght = 85\n",
      "Test Dataset lenght = 10\n",
      "Valid Dataset lenght = 12\n"
     ]
    }
   ],
   "source": [
    "Train_dataset, Test_dataset, Valid_dataset = split_dataset(dataset, 0.8, 0.1, 0.1)\n",
    "print(f\"Train Dataset lenght = {len(Train_dataset)}\\nTest Dataset lenght = {len(Test_dataset)}\\nValid Dataset lenght = {len(Valid_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c57c38",
   "metadata": {},
   "source": [
    "### Resnet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "960dbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resnet50 = tf.keras.applications.ResNet50(\n",
    "    include_top = False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape = (256,256,3),\n",
    "    classes = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1cd869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resnet50_Model = Sequential()\n",
    "Resnet50.trainable = False\n",
    "\n",
    "Resnet50_Model.add(Resnet50)\n",
    "Resnet50_Model.add(layers.Flatten())\n",
    "Resnet50_Model.add(layers.Dense(256, activation = 'relu'))\n",
    "Resnet50_Model.add(layers.Dense(4, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab4e56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33554688  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 57,143,428\n",
      "Trainable params: 33,555,716\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Resnet50_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a36a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resnet50_Model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5561cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "85/85 [==============================] - 193s 2s/step - loss: 5.3780 - accuracy: 0.8738 - val_loss: 0.4743 - val_accuracy: 0.9688\n",
      "Epoch 2/4\n",
      "85/85 [==============================] - 177s 2s/step - loss: 1.1510 - accuracy: 0.9493 - val_loss: 0.3771 - val_accuracy: 0.9792\n",
      "Epoch 3/4\n",
      "85/85 [==============================] - 175s 2s/step - loss: 0.2411 - accuracy: 0.9911 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/4\n",
      "85/85 [==============================] - 126s 1s/step - loss: 0.0673 - accuracy: 0.9963 - val_loss: 0.0817 - val_accuracy: 0.9948\n"
     ]
    }
   ],
   "source": [
    "Resnet50_history = Resnet50_Model.fit(\n",
    "    Train_dataset,\n",
    "    epochs = 4,\n",
    "    validation_data = Valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95b18c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 14s 1s/step - loss: 0.2090 - accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20898723602294922, 0.9750000238418579]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Resnet50_Score = Resnet50_Model.evaluate(Test_dataset)\n",
    "Resnet50_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14156e6b",
   "metadata": {},
   "source": [
    "### Resnet for Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e7fd172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohsin\\anaconda3\\envs\\Deep_learnings\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "Resnet50_Model.save(\"Cotton_Plant_Disease.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bf62c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
